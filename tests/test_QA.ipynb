{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/yul080/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/AD/yul080/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/AD/yul080/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,concatenate_datasets, Dataset,DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "from DMLP.models.my_transformers import MODEL_CLASS\n",
    "from DMLP.models.models import VAE, DDPM, MLPSkipNet, TransformerNet,VAE_DDPM\n",
    "from DMLP.train.reconstruction import *\n",
    "from DMLP.utils.ddpm_schedule import ddpm_schedule\n",
    "from DMLP.utils.random_init import weights_init_random\n",
    "from DMLP.train.train_function import train_vae_ddpm\n",
    "import numpy as np\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_encoder = AutoTokenizer.from_pretrained(\"prajjwal1/bert-small\")\n",
    "tokenizer_decoder = AutoTokenizer.from_pretrained(\"gpt2-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_dict = {'pad_token': '<PAD>', 'bos_token': '<BOS>', 'eos_token': '<EOS>', }\n",
    "num_added_toks = tokenizer_decoder.add_special_tokens(special_tokens_dict)\n",
    "gpt2_pad_token = tokenizer_decoder.convert_tokens_to_ids([tokenizer_decoder.pad_token])[0]\n",
    "gpt2_eos_token = tokenizer_decoder.convert_tokens_to_ids([tokenizer_decoder.eos_token])[0]\n",
    "gpt2_bos_token = tokenizer_decoder.convert_tokens_to_ids([tokenizer_decoder.bos_token])[0]\n",
    "bert_pad_token = tokenizer_encoder.pad_token_id\n",
    "gpt2_pad_token = tokenizer_decoder.pad_token_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/AD/yul080/DMLP/Data/socialiqa-train-dev/train_converted.jsonl') as f:\n",
    "    train = list((json.loads(data) for data in list(f)))\n",
    "\n",
    "with open('/home/AD/yul080/DMLP/Data/socialiqa-train-dev/dev_converted.jsonl') as f:\n",
    "    test = list((json.loads(data) for data in list(f)))\n",
    "# dataset = Dataset.from_dict({\"text\":train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    question = tokenizer_encoder(\n",
    "        (examples['context'] + ' ' + examples['question']).replace(\".\",\"\").replace(\"?\",\"\").replace(\":\",\"\").replace(\",\",\"\"), return_special_tokens_mask=True, truncation=True, max_length=512)\n",
    "    answer = tokenizer_decoder(\n",
    "            examples['answer'].replace(\" ''\",'').replace(\"`` \",''), return_special_tokens_mask=True, truncation=True, max_length=tokenizer_decoder.model_max_length\n",
    "            )\n",
    "    return {'question':question['input_ids'],'answer':[tokenizer_decoder.convert_tokens_to_ids([tokenizer_decoder.bos_token])[0]]+answer['input_ids']+[tokenizer_decoder.convert_tokens_to_ids([tokenizer_decoder.eos_token])[0]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_list(train)\n",
    "test_dataset = Dataset.from_list(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 33410/33410 [00:07<00:00, 4401.68 examples/s]\n",
      "Map: 100%|██████████| 1954/1954 [00:00<00:00, 4337.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(group_texts, batched=False, remove_columns=[\"context\"],num_proc=1)\n",
    "test_dataset = test_dataset.map(group_texts, batched=False, remove_columns=[\"context\"],num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_dataset = DatasetDict({'train':train_dataset,'test':test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    def __init__(self, encoder_token, decoder_token):\n",
    "        self.encoder_token = encoder_token\n",
    "        self.decoder_token = decoder_token\n",
    "    def __call__(self, batch):\n",
    "        question_ids_bert = pad_sequence([torch.tensor(f['question'], dtype=torch.long) for f in batch],\n",
    "                                  batch_first=True, padding_value=self.encoder_token)\n",
    "        answer_ids_gpt = pad_sequence([torch.tensor(f['answer'], dtype=torch.long) for f in batch],\n",
    "                                    batch_first=True, padding_value=self.decoder_token)\n",
    "        try:\n",
    "            token_lengths = torch.tensor([[len(f['question']), len(f['answer'])] for f in batch],\n",
    "                                        dtype=torch.long)\n",
    "        except:\n",
    "            token_lengths = torch.zeros((len(batch), 1091))\n",
    "            for i in range(len(batch)):\n",
    "                token_lengths[i, len(batch[i]['answer'])] = 1\n",
    "        return (question_ids_bert, answer_ids_gpt, token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "my_collator = MyCollator(bert_pad_token, gpt2_pad_token)\n",
    "eval_dataloader =  DataLoader(train_eval_dataset['test'], num_workers=0, collate_fn=my_collator,batch_size=batch_size)\n",
    "train_dataloader = DataLoader(train_eval_dataset['train'], num_workers=0, collate_fn=my_collator, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in eval_dataloader:\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101, 18961,  1996,  2961,  2766,  1037,  4062,  2058,  2005, 21485,\n",
       "           2006,  1996,  2346,  2339,  2106, 18961,  2079,  2023,   102]]),\n",
       " tensor([[50258,   568,   661,   836,   470,  3708,   284,  3049, 50259]]),\n",
       " tensor([[19,  9]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] aubrey the officer pulled a driver over for speeding on the road why did aubrey do this [SEP]'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_encoder.decode(a[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<BOS>so people don't drive to fast<EOS>\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_decoder.decode(a[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
